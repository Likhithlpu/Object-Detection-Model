{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPUTER VISION AND IOT INTERN\n",
    "# SPARKS FOUNDATION\n",
    "# NAME: Bala Likhith Kanigolla\n",
    "# Task: Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing The Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CV2:\n",
    "OpenCV is a huge open-source library for computer vision, machine learning, and image processing. OpenCV supports a wide variety of programming languages like Python, C++, Java, etc. It can process images and videos to identify objects, faces, or even the handwriting of a human\n",
    "#### Numpy:\n",
    "NumPy is a Python library used for working with arrays. It also has functions for working in domain of linear algebra, fourier transform, and matrices. NumPy was created in 2005 by Travis Oliphant. It is an open source project and you can use it freely. NumPy stands for Numerical Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Weights and the configuration file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is Yolov3:\n",
    "YOLOv3 is the version three of the YOLO system (YOLOv3 Paper). ... cfg file, and the pre-trained weights of the neural network are stored in yolov3. weights . There is a file called coco. names that has the list of 80 object class that the model will be able to detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=cv2.dnn.readNet('yolov3.weights','yolov3.cfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['person', 'bicycle', 'car', 'motorbike', 'aeroplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'sofa', 'pottedplant', 'bed', 'diningtable', 'toilet', 'tvmonitor', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n"
     ]
    }
   ],
   "source": [
    "with open('coco.names', 'r') as f:\n",
    "    classes =f.read().splitlines()\n",
    "    print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meathods\n",
    "### Image Feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('3.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width, _ = img.shape\n",
    "blob = cv2.dnn.blobFromImage(img, 1/255, (416,416), (0,0,0), swapRB=True, crop=False)\n",
    "net.setInput(blob)\n",
    "output_layers_names =net.getUnconnectedOutLayers()\n",
    "layerOutputs =net.forward(output_layers_names )\n",
    "boxes = []\n",
    "confidences = []\n",
    "class_ids = []\n",
    "for output in layerOutputs:\n",
    "    for detection in output:\n",
    "        scores = detection[5:]\n",
    "        class_id= np.argmax(scores)\n",
    "        confidence= scores[class_id]\n",
    "        if confidence> 0.5:\n",
    "            center_x=int(detection[0]*width)\n",
    "            center_y=int(detection[1]*height)\n",
    "            w = int(detection[2]*width)\n",
    "            h =int(detection[3]*height)\n",
    "\n",
    "            x = int(center_x - w/2)\n",
    "            y= int(center_y - h/2)\n",
    "\n",
    "            boxes.append([x,y,w,h])\n",
    "            confidences.append((float(confidence)))\n",
    "            class_ids.append(class_id)\n",
    "indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5,0.4)\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "colors = np.random.uniform(0, 255, size=(len(boxes), 3))\n",
    "if len(indexes)>0:\n",
    "    for i in indexes.flatten():\n",
    "        x, y, w, h =boxes[i]\n",
    "        label = str(classes[class_ids[i]])\n",
    "        confidence = str(round(confidences[i], 2))\n",
    "        color = colors[i]\n",
    "        cv2.rectangle(img, (x,y), (x+w, y+h), color, 2)\n",
    "        cv2.putText(img, label + \" \"*100+ confidence, (x, y+20), font, 1, (255,255,255), 1)\n",
    "cv2.imshow('Image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video Feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('traffic.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"chicago.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    _, img = cap.read()\n",
    "    height, width, _ = img.shape\n",
    "    blob = cv2.dnn.blobFromImage(img, 1/255, (416,416), (0,0,0), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    output_layers_names =net.getUnconnectedOutLayers()\n",
    "    layerOutputs =net.forward(output_layers_names )\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    class_ids = []\n",
    "    for output in layerOutputs:\n",
    "        for detection in output:\n",
    "            scores = detection[5:]\n",
    "            class_id= np.argmax(scores)\n",
    "            confidence= scores[class_id]\n",
    "            if confidence> 0.5:\n",
    "                center_x=int(detection[0]*width)\n",
    "                center_y=int(detection[1]*height)\n",
    "                w = int(detection[2]*width)\n",
    "                h =int(detection[3]*height)\n",
    "\n",
    "                x = int(center_x - w/2)\n",
    "                y= int(center_y - h/2)\n",
    "\n",
    "                boxes.append([x,y,w,h])\n",
    "                confidences.append((float(confidence)))\n",
    "                class_ids.append(class_id)\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5,0.4)\n",
    "    font = cv2.FONT_HERSHEY_PLAIN\n",
    "    colors = np.random.uniform(0, 255, size=(len(boxes), 3))\n",
    "    if len(indexes)>0:\n",
    "        for i in indexes.flatten():\n",
    "            x, y, w, h =boxes[i]\n",
    "            label = str(classes[class_ids[i]])\n",
    "            confidence = str(round(confidences[i], 2))\n",
    "            color = colors[i]\n",
    "            cv2.rectangle(img, (x,y), (x+w, y+h), color, 2)\n",
    "            cv2.putText(img, label + \" \"*100+ confidence, (x, y+20), font, 1, (255,255,255), 1)\n",
    "    cv2.imshow('Image', img)\n",
    "    cv2.waitKey(1)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
